{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9a543f-f0e7-489c-8896-ec7fbe57b36c",
   "metadata": {},
   "source": [
    "## only pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa389ff-3035-41c0-a207-050ae2d707fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  ank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frames to: E:\\removeBackground\\ank\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Ask for a name\n",
    "name = input(\"Enter your name: \")\n",
    "\n",
    "# Step 2: Create folder\n",
    "folder_path = os.path.join(os.getcwd(), name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "print(f\"Saving frames to: {folder_path}\")\n",
    "\n",
    "# Step 3: Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Step 4: Start Pose with segmentation\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                  model_complexity=1,\n",
    "                  enable_segmentation=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    frame_count = 0  # To save frames with unique names\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Pose estimation\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Create white background\n",
    "        bg_color = (255, 255, 255)\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = bg_color\n",
    "\n",
    "        if results.segmentation_mask is not None:\n",
    "            condition = results.segmentation_mask > 0.02\n",
    "            output_image = np.where(condition[..., None], image, bg_image)\n",
    "        else:\n",
    "            output_image = image\n",
    "\n",
    "        # Draw landmarks if present\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                output_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Step 5: Save each frame\n",
    "        filename = os.path.join(folder_path, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(filename, output_image)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Show preview\n",
    "        cv2.imshow('Pose with Background Removed', output_image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1cb65-f425-4bbc-9913-e4f0ccbdf2a1",
   "metadata": {},
   "source": [
    "## hand + pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80008cd2-e138-41c4-b6b7-72d88bfef055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  ankit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frames to: E:\\removeBackground\\ankit\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'enable_segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     19\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Use both Pose and Hands\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m                   model_complexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     24\u001b[0m                   enable_segmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m                   min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     26\u001b[0m                   min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pose, \\\n\u001b[1;32m---> 27\u001b[0m      \u001b[43mmp_hands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_num_hands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menable_segmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hands:\n\u001b[0;32m     33\u001b[0m     frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'enable_segmentation'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Ask for a name\n",
    "name = input(\"Enter your name: \")\n",
    "\n",
    "# Step 2: Create folder\n",
    "folder_path = os.path.join(os.getcwd(), name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "print(f\"Saving frames to: {folder_path}\")\n",
    "\n",
    "# Initialize MediaPipe modules\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Use both Pose and Hands\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                  model_complexity=1,\n",
    "                  enable_segmentation=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose, \\\n",
    "     mp_hands.Hands(static_image_mode=False,\n",
    "                    max_num_hands=2,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_rgb.flags.writeable = False\n",
    "\n",
    "        # Step 1: Pose estimation\n",
    "        pose_results = pose.process(image_rgb)\n",
    "\n",
    "        # Step 2: Hand detection\n",
    "        hand_results = hands.process(image_rgb)\n",
    "\n",
    "        image_rgb.flags.writeable = True\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Create white background\n",
    "        bg_image = np.ones(image_bgr.shape, dtype=np.uint8) * 255\n",
    "\n",
    "        # Use pose segmentation mask for background removal\n",
    "        if pose_results.segmentation_mask is not None:\n",
    "            condition = pose_results.segmentation_mask > 0.02\n",
    "            output_image = np.where(condition[..., None], image_bgr, bg_image)\n",
    "        else:\n",
    "            output_image = image_bgr\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        if pose_results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                output_image,\n",
    "                pose_results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Draw hand landmarks\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    output_image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Save frame to folder\n",
    "        filename = os.path.join(folder_path, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(filename, output_image)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Show preview\n",
    "        cv2.imshow('Pose + Hands with Background Removed', output_image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc8de9-264e-4e55-86e6-663a345b7780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
