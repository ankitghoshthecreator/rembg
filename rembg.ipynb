{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9050295d-c2b1-441b-895b-b97edbd57063",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e48c82-37a4-4f58-8541-7e9734534b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose and Drawing modules\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing webcam video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make pose detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('MediaPipe Pose Estimation', image)\n",
    "\n",
    "        # Break on 'q' key press\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23a9eb-d101-4d32-8a5f-4d4572d011d8",
   "metadata": {},
   "source": [
    "# realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af00d357-f822-4de0-b15f-2699689a59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Use MediaPipe Pose with segmentation enabled\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                  model_complexity=1,\n",
    "                  enable_segmentation=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Pose estimation\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Create white background image\n",
    "        bg_color = (255, 255, 255)  # white background\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = bg_color\n",
    "\n",
    "        # If segmentation mask is available\n",
    "        if results.segmentation_mask is not None:\n",
    "            condition = results.segmentation_mask > 0.1  # 0.1 = threshold for visibility\n",
    "\n",
    "            # Combine image and background using mask\n",
    "            output_image = np.where(condition[..., None], image, bg_image)\n",
    "        else:\n",
    "            output_image = image\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                output_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Show result\n",
    "        cv2.imshow('Pose with Background Removed', output_image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940a960-c61b-4cd8-bf61-1b83e51ad7c9",
   "metadata": {},
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c8e6d9-56fb-4d42-beb7-f429abd1b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the full path of the image to remove background from:  ag.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as output_no_bg.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ask user for image path\n",
    "img_path = input(\"Enter the full path of the image to remove background from: \").strip()\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(img_path):\n",
    "    print(\"Image not found. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Load input image\n",
    "image = cv2.imread(img_path)\n",
    "if image is None:\n",
    "    print(\"Failed to load image. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Convert to RGB for MediaPipe\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "with mp_pose.Pose(static_image_mode=True,\n",
    "                  model_complexity=2,\n",
    "                  enable_segmentation=True,\n",
    "                  min_detection_confidence=0.5) as pose:\n",
    "\n",
    "    results = pose.process(rgb_image)\n",
    "\n",
    "    if results.segmentation_mask is not None:\n",
    "        # Use mask to separate person from background\n",
    "        condition = results.segmentation_mask > 0.1\n",
    "\n",
    "        # Set background color (white in this case)\n",
    "        background_color = (255, 255, 255)\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = background_color\n",
    "\n",
    "        # Apply mask to get result\n",
    "        output_image = np.where(condition[..., None], image, bg_image)\n",
    "\n",
    "        # Show and save output\n",
    "        cv2.imshow(\"Background Removed\", output_image)\n",
    "        cv2.imwrite(\"output_no_bg.jpg\", output_image)\n",
    "        print(\"Saved as output_no_bg.jpg\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Could not generate segmentation mask.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e7491-0e7f-42dc-b25e-94745682a006",
   "metadata": {},
   "source": [
    "# manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2ec64-7536-4b2b-91ed-9d0cb0e0fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_path = input(\"image: \").strip()\n",
    "if not os.path.exists(img_path):\n",
    "    print(\"Image not found\")\n",
    "    exit()\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "h, w = image.shape[:2]\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_landmarks = mp_pose.PoseLandmark\n",
    "\n",
    "with mp_pose.Pose(static_image_mode=True,\n",
    "                  model_complexity=2,\n",
    "                  enable_segmentation=False,\n",
    "                  min_detection_confidence=0.5) as pose:\n",
    "\n",
    "    results = pose.process(rgb_image)\n",
    "\n",
    "    if not results.pose_landmarks:\n",
    "        print(\"not detected.\")\n",
    "        exit()\n",
    "\n",
    "    full_body_indices = [\n",
    "        pose_landmarks.NOSE,                \n",
    "        pose_landmarks.LEFT_SHOULDER,       \n",
    "        pose_landmarks.LEFT_HIP,            \n",
    "        pose_landmarks.LEFT_KNEE,           \n",
    "        pose_landmarks.LEFT_ANKLE,         \n",
    "        pose_landmarks.LEFT_HEEL,           \n",
    "        pose_landmarks.LEFT_FOOT_INDEX,     \n",
    "        pose_landmarks.LEFT_HIP,            \n",
    "        pose_landmarks.RIGHT_HIP,           \n",
    "        pose_landmarks.RIGHT_KNEE,          \n",
    "        pose_landmarks.RIGHT_ANKLE,         \n",
    "        pose_landmarks.RIGHT_HEEL,          \n",
    "        pose_landmarks.RIGHT_FOOT_INDEX,    \n",
    "        pose_landmarks.RIGHT_HIP,           \n",
    "        pose_landmarks.RIGHT_SHOULDER,      \n",
    "        pose_landmarks.RIGHT_ELBOW,         \n",
    "        pose_landmarks.RIGHT_WRIST,         \n",
    "        pose_landmarks.RIGHT_INDEX,         \n",
    "        pose_landmarks.RIGHT_SHOULDER,      \n",
    "        pose_landmarks.LEFT_SHOULDER,       \n",
    "        pose_landmarks.LEFT_ELBOW,         \n",
    "        pose_landmarks.LEFT_WRIST,          \n",
    "        pose_landmarks.LEFT_INDEX          \n",
    "    ]\n",
    "\n",
    "    polyline_pts = []\n",
    "    for idx in full_body_indices:\n",
    "        lm = results.pose_landmarks.landmark[idx]\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        polyline_pts.append((x, y))\n",
    "\n",
    "    polyline_pts = np.array(polyline_pts, dtype=np.int32)\n",
    "\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    # Step 1: Draw the pose polyline corridor (4cm = ~151 pixels)\n",
    "    corridor_thickness = 170\n",
    "    cv2.polylines(mask, [polyline_pts], isClosed=False, color=255, thickness=corridor_thickness)\n",
    "\n",
    "    # Step 2: Add extended torso rectangle\n",
    "    shoulder_left = results.pose_landmarks.landmark[11]\n",
    "    shoulder_right = results.pose_landmarks.landmark[12]\n",
    "    hip_left = results.pose_landmarks.landmark[23]\n",
    "    hip_right = results.pose_landmarks.landmark[24]\n",
    "\n",
    "    # Convert to pixel coordinates\n",
    "    sl_x, sl_y = int(shoulder_left.x * w), int(shoulder_left.y * h)\n",
    "    sr_x, sr_y = int(shoulder_right.x * w), int(shoulder_right.y * h)\n",
    "    hl_x, hl_y = int(hip_left.x * w), int(hip_left.y * h)\n",
    "    hr_x, hr_y = int(hip_right.x * w), int(hip_right.y * h)\n",
    "\n",
    "    # Extend shoulder points upward by 2.5 cm (~95 pixels)\n",
    "    cm_to_pixels = 37.8\n",
    "    shift = int(2.5 * cm_to_pixels)\n",
    "    sl_y -= shift\n",
    "    sr_y -= shift\n",
    "\n",
    "    torso_pts = np.array([[\n",
    "        (sl_x, sl_y),\n",
    "        (sr_x, sr_y),\n",
    "        (hr_x, hr_y),\n",
    "        (hl_x, hl_y)\n",
    "    ]], dtype=np.int32)\n",
    "\n",
    "    cv2.fillPoly(mask, torso_pts, 255)\n",
    "\n",
    "    mask_3ch = cv2.merge([mask, mask, mask])\n",
    "\n",
    "    output = np.where(mask_3ch == 255, image, 255)  # white background outside\n",
    "\n",
    "    # Show and save result\n",
    "    cv2.imshow(\"Pose Line + Extended Torso\", output)\n",
    "    cv2.imwrite(\"output_pose_and_extended_torso.jpg\", output)\n",
    "    print(\"saved as output_pose_and_extended_torso.jpg\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7aed7-0fee-41a9-814b-133371ef2e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
